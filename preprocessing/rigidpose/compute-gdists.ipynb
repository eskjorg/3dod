{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../..')\n",
    "#sys.path.append(os.path.join(os.path.dirname(os.path.dirname(__file__))))\n",
    "\n",
    "import pickle\n",
    "import shutil\n",
    "import yaml\n",
    "import gdist\n",
    "from lib.rigidpose.sixd_toolkit.pysixd import inout\n",
    "from lib.utils import listdir_nohidden\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import png\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIXD_PATH = '/home/lucas/datasets/pose-data/sixd/occluded-linemod-augmented2cc_gdists'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = inout.load_yaml(os.path.join(SIXD_PATH, 'models', 'models_info.yml'))\n",
    "models = {}\n",
    "for obj_id in models_info:\n",
    "    models[obj_id] = inout.load_ply(os.path.join(SIXD_PATH, 'models', 'obj_{:02}.ply'.format(obj_id)))\n",
    "    print(\"Obj {}: {} vertices, {} faces.\".format(obj_id, len(models[obj_id]['pts']), len(models[obj_id]['faces'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "- Using the SIXD model instead, since the other one is very rough, has 0.5M faces, disconnected components, and for some reason makes gdist library crash. SIXD model rotated into same coord system, hopefully without issues.\n",
    "- They do however look quite different... Would be better to re-render with models from SIXD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models[10] = inout.load_ply('/home/lucas/datasets/pose-data/sixd/bop-unzipped/hinterstoisser/models/obj_12.ply')\n",
    "#models[10] = inout.load_ply('/home/lucas/datasets/pose-data/ply-models-ascii/010_smooth_from_sixd_rotated.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_vtx(x, y, z, vertices):\n",
    "    assert vertices.shape[1] == 3\n",
    "    distances = np.linalg.norm(vertices - np.array([[x, y, z]]), axis=1)\n",
    "    vtx_idx = np.argmin(distances)\n",
    "    return vtx_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gdists_on_models(models, models_info):\n",
    "    gdists = {}\n",
    "    obj_cnt = 0\n",
    "    for obj_id, model in models.items():\n",
    "        obj_cnt += 1\n",
    "#         if obj_id != 10:\n",
    "#             continue\n",
    "        nbr_vtx = model['pts'].shape[0]\n",
    "        nbr_kp = len(models_info[obj_id]['kp_x'])\n",
    "        gdists[obj_id] = {}\n",
    "        for kp_idx, kp_coords in enumerate(zip(models_info[obj_id]['kp_x'], models_info[obj_id]['kp_y'], models_info[obj_id]['kp_z'])):\n",
    "#             if kp_idx != 10:\n",
    "#                 continue\n",
    "            kp_vtx_idx = find_closest_vtx(*kp_coords, model['pts'])\n",
    "            print(\"Obj {}/{}: {}, keypoint {}/{}\".format(obj_cnt, len(models), obj_id, kp_idx+1, nbr_kp))\n",
    "#             continue\n",
    "            gdists[obj_id][kp_idx] = gdist.compute_gdist(\n",
    "                model['pts'].astype(np.float64),\n",
    "                model['faces'].astype(np.int32),\n",
    "                source_indices = np.array([kp_vtx_idx], np.int32),\n",
    "                #target_indices = np.array(list(range(nbr_vtx)), np.int32),\n",
    "                #max_distance = 100.0,\n",
    "            )\n",
    "    #        colors = gdist_to_kp_per_vtx[:,np.newaxis]\n",
    "    #        colors = 255.999*(1.0-colors/np.max(colors))\n",
    "    #        models[obj_id]['colors'][:,:] = colors.astype('uint8')\n",
    "    #        inout.save_ply(\n",
    "    #            '/tmp/test.ply',\n",
    "    #            models[obj_id]['pts'],\n",
    "    #            pts_colors = models[obj_id]['colors'],\n",
    "    #            pts_normals = models[obj_id]['normals'],\n",
    "    #            faces = models[obj_id]['faces'],\n",
    "    #        )\n",
    "    #        break\n",
    "    #    break\n",
    "    return gdists\n",
    "gdists = compute_gdists_on_models(models, models_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(SIXD_PATH, 'models', 'gdists.yml'), 'w') as f:\n",
    "    yaml.dump(gdists, f, Dumper=yaml.CDumper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate gdists & normals per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "* Read keypoints. Find closest vertex?\n",
    "* For each object, for each vertex, compute and store geodesic distances to all keypoints\n",
    "* Loop through all corr maps. For each pixel, lookup and store gdist. Find closest vertex / vertices.\n",
    "* Store gdists & normal on each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use glob to find all segs. Determine corr paths as well & read them both.\n",
    "# Define paths to gdist and normal maps\n",
    "# Use seg & corrs to find closest vertex, and its gdist & normal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_surface(self, obj_id):\n",
    "    distances = np.linalg.norm(self.models[obj_id]['pts'] - keypoint[np.newaxis,:], axis=1)\n",
    "    closest_vtx_idx = np.argmin(distances)\n",
    "    # Overwrite keypoints with closest vertices:\n",
    "    return self.models[obj_id]['pts'][closest_vtx_idx_list,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return yaml.load(f, Loader=yaml.CLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_png(filename, dtype=None, nbr_channels=3):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = png.Reader(f).read()[2]\n",
    "        if dtype is not None:\n",
    "            img = np.vstack(map(dtype, data))\n",
    "        else:\n",
    "            img = np.vstack(data)\n",
    "    shape = img.shape\n",
    "    assert shape[1] % nbr_channels == 0\n",
    "    img = np.reshape(img, (shape[0], shape[1]//nbr_channels, nbr_channels))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_png(filename, dtype=None, nbr_channels=3):\n",
    "    with open(filename, 'wb') as f:\n",
    "        data = png.Writer(f).read()[2]\n",
    "        if dtype is not None:\n",
    "            img = np.vstack(map(dtype, data))\n",
    "        else:\n",
    "            img = np.vstack(data)\n",
    "    shape = img.shape\n",
    "    assert shape[1] % nbr_channels == 0\n",
    "    img = np.reshape(img, (shape[0], shape[1]//nbr_channels, nbr_channels))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSETS = [subset for subset in listdir_nohidden(SIXD_PATH) if subset.startswith('train') or subset.startswith('test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in SUBSETS:\n",
    "    if subset not in [\n",
    "        'train_unoccl',\n",
    "        #'train_occl',\n",
    "        #'test_occl',\n",
    "    ]:\n",
    "        continue\n",
    "    seqs = listdir_nohidden(os.path.join(SIXD_PATH, subset))\n",
    "    #if subset == 'train_unoccl':\n",
    "    #    seqs = ['driller']\n",
    "    #elif subset == 'train_occl':\n",
    "    #    seqs = ['ape']\n",
    "    #elif subset == 'test_occl':\n",
    "    #    seqs = ['benchviseblue']\n",
    "    for seq in seqs:\n",
    "        rgb_dir = os.path.join(SIXD_PATH, subset, seq, 'rgb')\n",
    "        instance_seg_dir = os.path.join(SIXD_PATH, subset, seq, 'instance_seg')\n",
    "        corr_dir = os.path.join(SIXD_PATH, subset, seq, 'obj')\n",
    "        #normals_dir = os.path.join(SIXD_PATH, subset, seq, 'normals')\n",
    "        vtx_idx_dir = os.path.join(SIXD_PATH, subset, seq, 'vtx_idx')\n",
    "\n",
    "        if os.path.exists(vtx_idx_dir):\n",
    "            shutil.rmtree(vtx_idx_dir)\n",
    "        os.makedirs(vtx_idx_dir)\n",
    "\n",
    "        gts = read_yaml(os.path.join(SIXD_PATH, subset, seq, 'gt.yml'))\n",
    "\n",
    "        fnames = list(sorted(listdir_nohidden(rgb_dir)))\n",
    "        for j, fname in enumerate(fnames):\n",
    "            img_idx = int(fname.split('.')[0])\n",
    "\n",
    "            if (j+1) % 10 == 0:\n",
    "                print(\"subset {}, seq {}, frame {}/{}\".format(subset, seq, j+1, len(fnames)))\n",
    "\n",
    "            instance_seg_path = os.path.join(instance_seg_dir, fname)\n",
    "            corr_path = os.path.join(corr_dir, fname)\n",
    "            #normals_path = os.path.join(normals_dir, fname)\n",
    "            vtx_idx_path = os.path.join(vtx_idx_dir, fname)\n",
    "\n",
    "            # Read segmentation & correspondence map\n",
    "            corr_map = read_png(corr_path, dtype=np.int16, nbr_channels=3).astype('float64') + 0.5\n",
    "            instance_seg = np.array(Image.open(instance_seg_path))\n",
    "\n",
    "            img_height, img_width = instance_seg.shape\n",
    "\n",
    "            # Vertex index map\n",
    "            vtx_idx_map = np.zeros((img_height, img_width), dtype='uint32')\n",
    "\n",
    "            instance_idx = 0\n",
    "            for gt in gts[img_idx]:\n",
    "                instance_idx += 1\n",
    "\n",
    "                mask = instance_seg == instance_idx\n",
    "                surface_pts = corr_map[mask,:]\n",
    "\n",
    "                obj_id = gt['obj_id']\n",
    "                nbr_kp = len(models_info[obj_id]['kp_x'])\n",
    "\n",
    "                # Lookup closest vertices to surface points\n",
    "                distance_matrix = cdist(surface_pts, models[obj_id]['pts'], metric='euclidean')\n",
    "                vtx_idx_map[mask] = np.argmin(distance_matrix, axis=1)\n",
    "\n",
    "            #assert vtx_idx_map.max() < 2**16\n",
    "            #Image.fromarray(vtx_idx_map.astype(np.uint16)).save(vtx_idx_path)\n",
    "            Image.fromarray(vtx_idx_map.astype(np.uint32)).save(vtx_idx_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dod-rigid",
   "language": "python",
   "name": "3dod-rigid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
